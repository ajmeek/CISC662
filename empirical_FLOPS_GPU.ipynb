{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d12c399cfef4099ba5a79a4dd40d47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d05872114b7464d9e922a515f1f0b8e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9dfd2bbc9424499a33cd7546f1dffe8",
              "IPY_MODEL_58dc517c70664dc58fb468302130414e",
              "IPY_MODEL_c6ed0fc9cae444958e7c3cb8e00dcb79"
            ]
          }
        },
        "1d05872114b7464d9e922a515f1f0b8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9dfd2bbc9424499a33cd7546f1dffe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9bc2d068b60346f1ba1ee7e5cc9e1dcf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b35221ad6d84152b906ae3489b9c0ca"
          }
        },
        "58dc517c70664dc58fb468302130414e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ca940ee4b473463a8337e3e56ce3462d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45a70a561a4e4fa3a07ee79202ac067b"
          }
        },
        "c6ed0fc9cae444958e7c3cb8e00dcb79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_352cb55e3bc540a2886950b2f7ea1c5f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:10&lt;00:00, 17644147.85it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa299a32f8714a1386e0ad8c118e10ec"
          }
        },
        "9bc2d068b60346f1ba1ee7e5cc9e1dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b35221ad6d84152b906ae3489b9c0ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca940ee4b473463a8337e3e56ce3462d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45a70a561a4e4fa3a07ee79202ac067b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "352cb55e3bc540a2886950b2f7ea1c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa299a32f8714a1386e0ad8c118e10ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameek2/CISC662/blob/master/empirical_FLOPS_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "This notebook adapted from Marius Hobbhahn, link: https://www.lesswrong.com/posts/jJApGWG95495pYM7C/how-to-measure-flop-s-for-neural-networks-empirically\n",
        "We are adapting this code to run on both GPU and TPUs to determine NN utilization for analysis in roofline models. This is for a project for our Computer Architecture class (CISC 662 at the University of Delaware)."
      ],
      "metadata": {
        "id": "XoFzprvnyRXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW5v_WhOERqz"
      },
      "source": [
        "### Measuring FLOPS in Pytorch\n",
        "\n",
        "To test FLOPS/s for currently used ML models we train multiple different classic NN architectures by training them for 10 epochs on CIFAR10.\n",
        "\n",
        "By reconnecting our Colab instance a bunch of times, we will try to get different GPUs to make the process comparable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQnW0HP5D2dc",
        "outputId": "c73bd9ac-67ba-46ae-d031-af362262c11c"
      },
      "source": [
        "### set up google files\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) \n",
        "\n",
        "file_location = '/content/drive/My Drive/Parameters, Compute and Data Trends in Machine Learning/empirical_FLOPs/'\n",
        "data_file_location = file_location + 'data/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFkpuIKYEMmy",
        "outputId": "804e1bec-6099-4794-9ec6-e1c1894c101f"
      },
      "source": [
        "!nvidia-smi\n",
        "#Tesla P100-PCIE..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 27 11:56:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgHriJayMGTE",
        "outputId": "9d5b3731-fb42-435e-c633-2aab17e120d2"
      },
      "source": [
        "!pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git\n",
        "!pip install -U 'git+https://github.com/facebookresearch/fvcore'\n",
        "!pip install onnx -U\n",
        "!pip install fprint\n",
        "!pip install pthflops -U\n",
        "!pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/sovrasov/flops-counter.pytorch.git\n",
            "  Cloning https://github.com/sovrasov/flops-counter.pytorch.git to /tmp/pip-req-build-tuhvn20x\n",
            "  Running command git clone -q https://github.com/sovrasov/flops-counter.pytorch.git /tmp/pip-req-build-tuhvn20x\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ptflops==0.6.6) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ptflops==0.6.6) (3.10.0.2)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.6.6-py3-none-any.whl size=9738 sha256=08cd0f66940ee97753d9908c2ca13414804c82bb4070b5eae4544f26592ac35c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sn3dvzom/wheels/e6/b6/9a/e2724c6623e6a32e8346bb8a4fdcc9656cef179ca17568ff6e\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.6.6\n",
            "Collecting git+https://github.com/facebookresearch/fvcore\n",
            "  Cloning https://github.com/facebookresearch/fvcore to /tmp/pip-req-build-b33yfve6\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore /tmp/pip-req-build-b33yfve6\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (1.19.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (4.62.3)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (0.8.9)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5-py3-none-any.whl size=65106 sha256=4734caafd422474e1890372c78eaa8376c62d01e82e75b9a2c5b6398ef3624f9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jsy39661/wheels/1c/80/2d/315cfb0174b5497db94b1a3c33b95db050f9172f1467171992\n",
            "Successfully built fvcore\n",
            "Installing collected packages: pyyaml, portalocker, yacs, iopath, fvcore\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed fvcore-0.1.5 iopath-0.1.9 portalocker-2.3.2 pyyaml-6.0 yacs-0.1.8\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.10.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.10.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.10.2\n",
            "Collecting fprint\n",
            "  Downloading fprint-1.0.tar.gz (1.3 kB)\n",
            "Building wheels for collected packages: fprint\n",
            "  Building wheel for fprint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fprint: filename=fprint-1.0-py3-none-any.whl size=2050 sha256=cb104e2fa4d0c1726aaa79695e08cfa7129a603ec2fb0bde2908deaa380c1d0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/59/ad/409a37134a158c16593295f1451095d2e0af91c4ce42810c93\n",
            "Successfully built fprint\n",
            "Installing collected packages: fprint\n",
            "Successfully installed fprint-1.0\n",
            "Collecting pthflops\n",
            "  Downloading pthflops-0.4.1.tar.gz (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pthflops) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pthflops) (3.10.0.2)\n",
            "Building wheels for collected packages: pthflops\n",
            "  Building wheel for pthflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pthflops: filename=pthflops-0.4.1-py3-none-any.whl size=10063 sha256=4047a56de836ec49f6173d6a2d0236af9af7c6824940031fb0e8ffb14b618138\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/41/05/475bdaebaaf3a44f25367a8dc0ac9d4b8edbb7f5fa19724c70\n",
            "Successfully built pthflops\n",
            "Installing collected packages: pthflops\n",
            "Successfully installed pthflops-0.4.1\n",
            "Collecting git+https://github.com/Lyken17/pytorch-OpCounter.git\n",
            "  Cloning https://github.com/Lyken17/pytorch-OpCounter.git to /tmp/pip-req-build-y3_rbnxi\n",
            "  Running command git clone -q https://github.com/Lyken17/pytorch-OpCounter.git /tmp/pip-req-build-y3_rbnxi\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from thop==0.0.5-2111271156) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->thop==0.0.5-2111271156) (3.10.0.2)\n",
            "Building wheels for collected packages: thop\n",
            "  Building wheel for thop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thop: filename=thop-0.0.5.post2111271156-py3-none-any.whl size=14775 sha256=c1d9ca513932558a1a6703446f04591ac5eb8398aa015ba9762f49463b65aedf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bkqefrzv/wheels/aa/e7/25/c280567dc2e6a1f3aadf802f16129960793c1bc889dbd8ee4e\n",
            "Successfully built thop\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.0.5.post2111271156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "496-iLzWEzUN"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "0d12c399cfef4099ba5a79a4dd40d47f",
            "1d05872114b7464d9e922a515f1f0b8e",
            "e9dfd2bbc9424499a33cd7546f1dffe8",
            "58dc517c70664dc58fb468302130414e",
            "c6ed0fc9cae444958e7c3cb8e00dcb79",
            "9bc2d068b60346f1ba1ee7e5cc9e1dcf",
            "3b35221ad6d84152b906ae3489b9c0ca",
            "ca940ee4b473463a8337e3e56ce3462d",
            "45a70a561a4e4fa3a07ee79202ac067b",
            "352cb55e3bc540a2886950b2f7ea1c5f",
            "fa299a32f8714a1386e0ad8c118e10ec"
          ]
        },
        "id": "_f2nJxbuE42Q",
        "outputId": "7ea1e1d2-3fae-4755-ed8d-c6c0372f20fe"
      },
      "source": [
        "### import dataset\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "batch_size_default = 128\n",
        "\n",
        "CIFAR10_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "CIFAR10_testloader = torch.utils.data.DataLoader(CIFAR10_testset, batch_size=batch_size_default,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d12c399cfef4099ba5a79a4dd40d47f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ii-HlAoE-QX"
      },
      "source": [
        "### import different models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TestNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 5, 10)\n",
        "        self.conv2 = nn.Conv2d(5, 6, 10)\n",
        "        self.fc1 = nn.Linear(254616, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "test_net = TestNet().cuda()\n",
        "\n",
        "resnet18 = models.resnet18(num_classes=10).cuda()\n",
        "resnet34 = models.resnet34(num_classes=10).cuda()\n",
        "resnet50 = models.resnet50(num_classes=10).cuda()\n",
        "resnet101 = models.resnet101(num_classes=10).cuda()\n",
        "resnet152 = models.resnet152(num_classes=10).cuda()\n",
        "\n",
        "vgg11 = models.vgg11(num_classes=10).cuda()\n",
        "vgg13 = models.vgg13(num_classes=10).cuda()\n",
        "vgg16 = models.vgg16(num_classes=10).cuda()\n",
        "vgg19 = models.vgg19(num_classes=10).cuda()\n",
        "\n",
        "wide_resnet50_2 = models.wide_resnet50_2(num_classes=10).cuda()\n",
        "alexnet = models.alexnet(num_classes=10).cuda()\n",
        "mobilenet_v2 = models.mobilenet_v2(num_classes=10).cuda()\n",
        "efficientnet_b0 = models.efficientnet_b0(num_classes=10).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Krj8YWMALH"
      },
      "source": [
        "### set up flop counting libraries\n",
        "import ptflops\n",
        "import fvcore\n",
        "from pthflops import count_ops#\n",
        "from ptflops import get_model_complexity_info\n",
        "from fvcore.nn import FlopCountAnalysis, parameter_count\n",
        "from thop.profile import profile as thop_profile\n",
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKXBPINSrL46",
        "outputId": "08e13b5e-87d0-4fcc-872d-6ab55ec714e2"
      },
      "source": [
        "# using fvcore\n",
        "def get_flops_fvcore_per_layer(model, inputs=(torch.randn((1,3,224,224)).cuda(),)):\n",
        "\n",
        "    FMAs_per_layer = FlopCountAnalysis(model, inputs).by_module_and_operator()\n",
        "    return(FMAs_per_layer)\n",
        "\n",
        "def get_flops_ptflops_per_layer(model, input_dims=(3, 224, 224)):\n",
        "\n",
        "    with torch.cuda.device(0):\n",
        "        FMAs, _ = get_model_complexity_info(model, input_dims, as_strings=False,\n",
        "                                            print_per_layer_stat=True, verbose=False)\n",
        "    return(FMAs, _)\n",
        "\n",
        "print(get_flops_fvcore_per_layer(vgg13, inputs=(torch.randn((1,3,224,224)).cuda(),)))\n",
        "print(get_flops_ptflops_per_layer(vgg13, input_dims=(3, 224, 224)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsupported operator aten::max_pool2d encountered 5 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': Counter({'conv': 11184832512, 'linear': 119578624, 'adaptive_avg_pool2d': 25088}), 'features': Counter({'conv': 11184832512}), 'features.0': Counter({'conv': 86704128}), 'features.1': Counter(), 'features.2': Counter({'conv': 1849688064}), 'features.3': Counter(), 'features.4': Counter(), 'features.5': Counter({'conv': 924844032}), 'features.6': Counter(), 'features.7': Counter({'conv': 1849688064}), 'features.8': Counter(), 'features.9': Counter(), 'features.10': Counter({'conv': 924844032}), 'features.11': Counter(), 'features.12': Counter({'conv': 1849688064}), 'features.13': Counter(), 'features.14': Counter(), 'features.15': Counter({'conv': 924844032}), 'features.16': Counter(), 'features.17': Counter({'conv': 1849688064}), 'features.18': Counter(), 'features.19': Counter(), 'features.20': Counter({'conv': 462422016}), 'features.21': Counter(), 'features.22': Counter({'conv': 462422016}), 'features.23': Counter(), 'features.24': Counter(), 'avgpool': Counter({'adaptive_avg_pool2d': 25088}), 'classifier': Counter({'linear': 119578624}), 'classifier.0': Counter({'linear': 102760448}), 'classifier.1': Counter(), 'classifier.2': Counter(), 'classifier.3': Counter({'linear': 16777216}), 'classifier.4': Counter(), 'classifier.5': Counter(), 'classifier.6': Counter({'linear': 40960})}\n",
            "VGG(\n",
            "  128.992 M, 100.000% Params, 11.335 GMac, 100.000% MACs, \n",
            "  (features): Sequential(\n",
            "    9.405 M, 7.291% Params, 11.215 GMac, 98.945% MACs, \n",
            "    (0): Conv2d(0.002 M, 0.001% Params, 0.09 GMac, 0.793% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(0.0 M, 0.000% Params, 0.003 GMac, 0.028% MACs, inplace=True)\n",
            "    (2): Conv2d(0.037 M, 0.029% Params, 1.853 GMac, 16.347% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(0.0 M, 0.000% Params, 0.003 GMac, 0.028% MACs, inplace=True)\n",
            "    (4): MaxPool2d(0.0 M, 0.000% Params, 0.003 GMac, 0.028% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(0.074 M, 0.057% Params, 0.926 GMac, 8.173% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.014% MACs, inplace=True)\n",
            "    (7): Conv2d(0.148 M, 0.114% Params, 1.851 GMac, 16.332% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.014% MACs, inplace=True)\n",
            "    (9): MaxPool2d(0.0 M, 0.000% Params, 0.002 GMac, 0.014% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(0.295 M, 0.229% Params, 0.926 GMac, 8.166% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.007% MACs, inplace=True)\n",
            "    (12): Conv2d(0.59 M, 0.457% Params, 1.85 GMac, 16.325% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.007% MACs, inplace=True)\n",
            "    (14): MaxPool2d(0.0 M, 0.000% Params, 0.001 GMac, 0.007% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(1.18 M, 0.915% Params, 0.925 GMac, 8.163% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.004% MACs, inplace=True)\n",
            "    (17): Conv2d(2.36 M, 1.829% Params, 1.85 GMac, 16.322% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.004% MACs, inplace=True)\n",
            "    (19): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.004% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (20): Conv2d(2.36 M, 1.829% Params, 0.463 GMac, 4.080% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
            "    (22): Conv2d(2.36 M, 1.829% Params, 0.463 GMac, 4.080% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
            "    (24): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    119.587 M, 92.709% Params, 0.12 GMac, 1.055% MACs, \n",
            "    (0): Linear(102.765 M, 79.667% Params, 0.103 GMac, 0.907% MACs, in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
            "    (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (3): Linear(16.781 M, 13.010% Params, 0.017 GMac, 0.148% MACs, in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
            "    (5): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (6): Linear(0.041 M, 0.032% Params, 0.0 GMac, 0.000% MACs, in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "(11335059978.0, 128991818)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnN6C-mzb2cy"
      },
      "source": [
        "### returns the flops and number of parameters of a model\n",
        "# using ptflops\n",
        "def get_flops_ptflops(model, input_dims=(3, 224, 224)):\n",
        "\n",
        "    with torch.cuda.device(0):\n",
        "        macs, num_params = get_model_complexity_info(model, input_dims, as_strings=False,\n",
        "                                            print_per_layer_stat=False, verbose=False)\n",
        "    return(macs, num_params)\n",
        "\n",
        "# using fvcore\n",
        "def get_flops_fvcore(model, inputs=(torch.randn((1,3,224,224)),)):\n",
        "\n",
        "    flops = FlopCountAnalysis(model, inputs)\n",
        "    total_flops = flops.total()\n",
        "    num_params = parameter_count(model)['']\n",
        "    return(total_flops, num_params)\n",
        "\n",
        "# using thop\n",
        "def get_flops_thop(model, inputs=(torch.randn((1,3,224,224)),)):\n",
        "\n",
        "    macs, params = thop_profile(model, inputs=inputs)\n",
        "    return(macs, params)\n",
        "\n",
        "# using pthflops\n",
        "def get_flops_pthflops(model, inputs=torch.randn(1,3,224,224)):\n",
        "\n",
        "    flops = count_ops(model, inputs)\n",
        "    return(flops[0])\n",
        "\n",
        "\n",
        "# using the profiler\n",
        "def get_flops_profiler_old(model, inputs=(torch.randn((1,3,224,224)),)):\n",
        "\n",
        "    with profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ],\n",
        "        with_flops=True) as prof:\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "\n",
        "    events = prof.events()\n",
        "    flops = sum([int(evt.flops) for evt in events]) \n",
        "    flops = flops / 2 # divide by 2 because of FMAs (see text)\n",
        "    return(flops)\n",
        "\n",
        "    # using the profiler\n",
        "def get_flops_profiler(model, inputs=(torch.randn((1,3,224,224)),)):\n",
        "\n",
        "    # warm up cuda memory allocator, recommended here: https://github.com/pytorch/pytorch/blob/master/torch/autograd/profiler.py\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    with torch.profiler.profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ],\n",
        "        with_flops=True) as prof:\n",
        "            with record_function(\"model_inference\"):\n",
        "                outputs = model(inputs)\n",
        "\n",
        "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
        "    events = prof.events()\n",
        "    flops = sum([int(evt.flops) for evt in events]) \n",
        "    flops = flops / 2 # divide by 2 because of FMAs (see text)\n",
        "    return(flops)\n",
        "\n",
        "def get_flops_profiler_bw(model, inputs=(torch.randn((1,3,224,224)),), y=torch.tensor([0]).cuda()):\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    # warm up cuda memory allocator, recommended here: https://github.com/pytorch/pytorch/blob/master/torch/autograd/profiler.py\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    ### measure only backward pass\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    with torch.profiler.profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ],\n",
        "        with_flops=True) as prof:\n",
        "            with record_function(\"model_inference\"):\n",
        "                loss = criterion(outputs, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "\n",
        "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
        "    events = prof.events()\n",
        "    flops = sum([int(evt.flops) for evt in events]) \n",
        "    flops = flops / 2 # divide by 2 because of FMAs (see text)\n",
        "    return(flops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFN5a2gaZavt",
        "outputId": "93af5646-a3bb-4647-9ab8-844885226f43"
      },
      "source": [
        "#flops_profiler = get_flops_profiler(resnet18, inputs=torch.randn((1,3,224,224)).cuda())\n",
        "#print(\"profiler: \", flops_profiler)\n",
        "\n",
        "flops_profiler = get_flops_profiler_bw(resnet18, inputs=torch.randn((1,3,224,224)).cuda())\n",
        "print(\"profiler: \", flops_profiler)\n",
        "### doesn't seem to measure the backward pass ... "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  Total KFLOPs  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "autograd::engine::evaluate_function: CudnnConvolutio...         0.02%     487.000us         0.33%       7.124ms     356.200us       0.000us         0.00%       2.571ms     128.550us            20            --  \n",
            "                              CudnnConvolutionBackward0         0.02%     388.000us         0.30%       6.399ms     319.950us       0.000us         0.00%       2.543ms     127.150us            20            --  \n",
            "                       aten::cudnn_convolution_backward         0.02%     426.000us         0.28%       6.011ms     300.550us       0.000us         0.00%       2.543ms     127.150us            20            --  \n",
            "                aten::cudnn_convolution_backward_weight         0.05%       1.104ms         0.17%       3.593ms     179.650us       1.391ms        36.39%       1.391ms      69.550us            20            --  \n",
            "                 aten::cudnn_convolution_backward_input         0.07%       1.446ms         0.09%       1.992ms     104.842us       1.152ms        30.13%       1.152ms      60.632us            19            --  \n",
            "void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3...         0.00%       0.000us         0.00%       0.000us       0.000us     720.000us        18.83%     720.000us      72.000us            10            --  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     707.000us        18.49%     707.000us       5.356us           132            --  \n",
            "                                             aten::add_         0.05%       1.176ms         0.11%       2.258ms      18.210us     679.000us        17.76%     679.000us       5.476us           124            --  \n",
            "                                        model_inference         0.73%      15.731ms        99.35%        2.132s        2.132s       0.000us         0.00%     362.000us     362.000us             1            --  \n",
            "autograd::engine::evaluate_function: CudnnBatchNormB...         0.02%     369.000us         0.10%       2.174ms     108.700us       0.000us         0.00%     352.000us      17.600us            20            --  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.146s\n",
            "Self CUDA time total: 3.823ms\n",
            "\n",
            "profiler:  474368.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2AuVIi0xyls",
        "outputId": "e4587574-59a3-48ad-b28e-9cb5da09f1b1"
      },
      "source": [
        "def get_flops_profiler_full_table(model, inputs=torch.randn(1,3,224,224).cuda()):\n",
        "\n",
        "    # warm up cuda memory allocator, recommended here: https://github.com/pytorch/pytorch/blob/master/torch/autograd/profiler.py\n",
        "    #outputs = model(inputs)\n",
        "\n",
        "    with torch.profiler.profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ],\n",
        "        with_flops=True) as prof:\n",
        "            with record_function(\"model_inference\"):\n",
        "                outputs = model(inputs)\n",
        "\n",
        "    print(prof.key_averages().table(row_limit=1000))\n",
        "    #print(prof.events())\n",
        "    events = prof.events()\n",
        "    flops = sum([int(evt.flops) for evt in events]) \n",
        "    flops = flops / 2 # divide by 2 because of FMAs (see text)\n",
        "    return(flops)\n",
        "\n",
        "get_flops_profiler_full_table(alexnet, inputs=torch.randn(1,3,224,224).cuda())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  Total MFLOPs  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::zeros         0.64%      24.000us         0.82%      31.000us      31.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "                                            aten::empty         1.03%      39.000us         1.03%      39.000us       4.875us       0.000us         0.00%       0.000us       0.000us             8            --  \n",
            "                                            aten::zero_         0.05%       2.000us         0.05%       2.000us       2.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "                                        model_inference        19.32%     729.000us        98.89%       3.732ms       3.732ms       0.000us         0.00%       1.201ms       1.201ms             1            --  \n",
            "                                           aten::conv2d         0.90%      34.000us        47.54%       1.794ms     358.800us       0.000us         0.00%     605.000us     121.000us             5      1311.133  \n",
            "                                      aten::convolution         1.27%      48.000us        46.63%       1.760ms     352.000us       0.000us         0.00%     605.000us     121.000us             5            --  \n",
            "                                     aten::_convolution         2.99%     113.000us        45.36%       1.712ms     342.400us       0.000us         0.00%     605.000us     121.000us             5            --  \n",
            "                                aten::cudnn_convolution        29.73%       1.122ms        35.88%       1.354ms     270.800us     577.000us        48.04%     577.000us     115.400us             5            --  \n",
            "                                          aten::resize_         0.48%      18.000us         0.48%      18.000us       1.636us       0.000us         0.00%       0.000us       0.000us            11            --  \n",
            "                                        cudaEventRecord         0.45%      17.000us         0.45%      17.000us       2.833us       0.000us         0.00%       0.000us       0.000us             6            --  \n",
            "                                       cudaLaunchKernel        12.29%     464.000us        12.29%     464.000us      14.968us       0.000us         0.00%       0.000us       0.000us            31            --  \n",
            "void implicit_convolve_sgemm<float, float, 128, 5, 5...         0.00%       0.000us         0.00%       0.000us       0.000us      72.000us         6.00%      72.000us      72.000us             1            --  \n",
            "                                          aten::reshape         1.01%      38.000us         2.09%      79.000us      15.800us       0.000us         0.00%       0.000us       0.000us             5            --  \n",
            "                                   aten::_reshape_alias         1.27%      48.000us         1.27%      48.000us       8.000us       0.000us         0.00%       0.000us       0.000us             6            --  \n",
            "                                             aten::add_         2.62%      99.000us         4.40%     166.000us      33.200us      28.000us         2.33%      28.000us       5.600us             5            --  \n",
            "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      28.000us         2.33%      28.000us       5.600us             5            --  \n",
            "                                            aten::relu_         2.78%     105.000us         8.35%     315.000us      45.000us       0.000us         0.00%      13.000us       1.857us             7            --  \n",
            "                                       aten::clamp_min_         1.09%      41.000us         5.56%     210.000us      30.000us       0.000us         0.00%      13.000us       1.857us             7            --  \n",
            "                                        aten::clamp_min         2.36%      89.000us         4.48%     169.000us      24.143us      13.000us         1.08%      13.000us       1.857us             7            --  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      13.000us         1.08%      13.000us       1.857us             7            --  \n",
            "                                       aten::max_pool2d         0.72%      27.000us         4.32%     163.000us      54.333us       0.000us         0.00%      17.000us       5.667us             3            --  \n",
            "                          aten::max_pool2d_with_indices         2.60%      98.000us         3.60%     136.000us      45.333us      17.000us         1.42%      17.000us       5.667us             3            --  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us      17.000us         1.42%      17.000us       5.667us             3            --  \n",
            "void cudnn::cnn::im2col4d_kernel<float, long>(cudnn:...         0.00%       0.000us         0.00%       0.000us       0.000us      70.000us         5.83%      70.000us      70.000us             1            --  \n",
            "void explicit_convolve_sgemm<float, int, 1024, 5, 5,...         0.00%       0.000us         0.00%       0.000us       0.000us     144.000us        11.99%     144.000us     144.000us             1            --  \n",
            "void cudnn::winograd::generateWinogradTilesKernel<1,...         0.00%       0.000us         0.00%       0.000us       0.000us      50.000us         4.16%      50.000us      16.667us             3            --  \n",
            "maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_rel...         0.00%       0.000us         0.00%       0.000us       0.000us     241.000us        20.07%     241.000us      80.333us             3            --  \n",
            "                              aten::adaptive_avg_pool2d         0.13%       5.000us         1.51%      57.000us      57.000us       0.000us         0.00%       7.000us       7.000us             1            --  \n",
            "                             aten::_adaptive_avg_pool2d         0.66%      25.000us         1.38%      52.000us      52.000us       7.000us         0.58%       7.000us       7.000us             1            --  \n",
            "void at::native::(anonymous namespace)::adaptive_ave...         0.00%       0.000us         0.00%       0.000us       0.000us       7.000us         0.58%       7.000us       7.000us             1            --  \n",
            "                                          aten::flatten         0.19%       7.000us         0.37%      14.000us      14.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "                                          aten::dropout         0.64%      24.000us         5.33%     201.000us     100.500us       0.000us         0.00%      15.000us       7.500us             2            --  \n",
            "                                   aten::_fused_dropout         1.70%      64.000us         4.69%     177.000us      88.500us      15.000us         1.25%      15.000us       7.500us             2            --  \n",
            "                                       aten::empty_like         0.53%      20.000us         1.75%      66.000us      16.500us       0.000us         0.00%       0.000us       0.000us             4            --  \n",
            "                                    aten::empty_strided         1.22%      46.000us         1.22%      46.000us      11.500us       0.000us         0.00%       0.000us       0.000us             4            --  \n",
            "                                  cudaStreamIsCapturing         0.08%       3.000us         0.08%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us             2            --  \n",
            "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      15.000us         1.25%      15.000us       7.500us             2            --  \n",
            "                                           aten::linear         1.19%      45.000us        12.11%     457.000us     152.333us       0.000us         0.00%     544.000us     181.333us             3            --  \n",
            "                                                aten::t         0.79%      30.000us         1.32%      50.000us      16.667us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                                        aten::transpose         0.40%      15.000us         0.53%      20.000us       6.667us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                                       aten::as_strided         0.19%       7.000us         0.19%       7.000us       1.167us       0.000us         0.00%       0.000us       0.000us             6            --  \n",
            "                                            aten::addmm         5.99%     226.000us         9.59%     362.000us     120.667us     544.000us        45.30%     544.000us     181.333us             3       109.134  \n",
            "                                           aten::expand         0.50%      19.000us         0.56%      21.000us       7.000us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                                        cudaMemcpyAsync         1.64%      62.000us         1.64%      62.000us      20.667us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      11.000us         0.92%      11.000us       3.667us             3            --  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.16%       6.000us         0.16%       6.000us       2.000us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                                         cudaEventQuery         0.11%       4.000us         0.11%       4.000us       4.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "void gemv2T_kernel_val<int, int, float, float, float...         0.00%       0.000us         0.00%       0.000us       0.000us     347.000us        28.89%     347.000us     347.000us             1            --  \n",
            "void splitKreduce_kernel<float, float, float, float>...         0.00%       0.000us         0.00%       0.000us       0.000us       7.000us         0.58%       7.000us       7.000us             1            --  \n",
            "void gemv2T_kernel_val<int, int, float, float, float...         0.00%       0.000us         0.00%       0.000us       0.000us     179.000us        14.90%     179.000us      89.500us             2            --  \n",
            "                                  cudaDeviceSynchronize         0.29%      11.000us         0.29%      11.000us      11.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 3.774ms\n",
            "Self CUDA time total: 1.201ms\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "710133440.0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvP9WFhExmBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63942700-496b-47aa-d9a1-199d3dba5567"
      },
      "source": [
        "### test for TestNet\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(test_net, input_dims=(3, 224, 224))\n",
        "print(\"ptflops: \", flops_ptflops, \"num_params: \", num_params_ptflops)\n",
        "\n",
        "flops_fvcore, num_params_fvcore = get_flops_fvcore(test_net, inputs=(torch.randn((1,3,224,224)).cuda(),))\n",
        "print(\"fvcore: \", flops_fvcore, \"num_params: \", num_params_fvcore)\n",
        "\n",
        "#flops_thop, num_params_thop = get_flops_thop(test_net, inputs=(torch.randn((1,3,224,224)),))\n",
        "#print(\"thop: \", flops_thop, \"num_params: \", num_params_thop)\n",
        "# some problem with fprint\n",
        "\n",
        "flops_pthflops = get_flops_pthflops(test_net, inputs=torch.randn(1,3,224,224).cuda())\n",
        "print(\"pthflops: \", flops_pthflops)\n",
        "\n",
        "flops_profiler = get_flops_profiler(test_net, inputs=torch.randn((1,3,224,224)).cuda())\n",
        "print(\"profiler: \", flops_profiler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptflops:  199677411.0 num_params:  2550681\n",
            "fvcore:  199191660 num_params:  2550681\n",
            "OperationOPS         \n",
            "------  ----------  \n",
            "conv1   69568625    \n",
            "conv2   127562616   \n",
            "fc1     2546170     \n",
            "-----   ---------   \n",
            "Input size: (1, 3, 224, 224)\n",
            "199,677,411 FLOPs or approx. 0.20 GFLOPs\n",
            "pthflops:  199677411\n",
            "profiler:  199191660.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4ttFmxP2tYz"
      },
      "source": [
        "from torch.autograd import DeviceType\n",
        "\n",
        "def get_time_profiler(profiler):\n",
        "\n",
        "    events = profiler.events()\n",
        "    sum_self_cuda_time_total = 0\n",
        "    for evt in events:\n",
        "        if evt.device_type == DeviceType.CPU:\n",
        "            # in legacy profiler, kernel info is stored in cpu events\n",
        "            if evt.is_legacy:\n",
        "                sum_self_cuda_time_total += evt.self_cuda_time_total\n",
        "        elif evt.device_type == DeviceType.CUDA:\n",
        "            # in kineto profiler, there're events with the correct device type (e.g. CUDA)\n",
        "            sum_self_cuda_time_total += evt.self_cuda_time_total\n",
        "\n",
        "    return(sum_self_cuda_time_total)\n",
        "\n",
        "def get_time_epoch_profiler(model, trainloader): \n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    ### measure time\n",
        "    print(\"measure time\")\n",
        "    with torch.profiler.profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ]) as prof:\n",
        "        for x,y in trainloader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    time_ = get_time_profiler(profiler=prof)\n",
        "    return(time_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0UVJU3B_Gc5"
      },
      "source": [
        "### test with TestNet\n",
        "#time_testnet = get_time_epoch_profiler(test_net, CIFAR10_testloader)\n",
        "#print(time_testnet / 1e6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZhAtMh4FAQP"
      },
      "source": [
        "### compute flops for one forward pass with one datapoint for all methods\n",
        "def get_flops_forward_all_methods(model): \n",
        "\n",
        "    flops_ptflops, num_params_ptflops = get_flops_ptflops(model, input_dims=(3, 224, 224))\n",
        "    flops_fvcore, num_params_fvcore = get_flops_fvcore(model, inputs=(torch.randn((1,3,224,224)).cuda(),))\n",
        "    flops_pthflops = get_flops_pthflops(model, inputs=torch.randn(1,3,224,224).cuda())\n",
        "    flops_profiler = get_flops_profiler(model, inputs=torch.randn((1,3,224,224)).cuda())\n",
        "\n",
        "    return(flops_ptflops, flops_fvcore, flops_pthflops, flops_profiler, num_params_fvcore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkshX_ArFapr"
      },
      "source": [
        "### run the function for multiple models and batch_sizes\n",
        "\n",
        "def compare_model_batch_sizes(model, model_name, batch_sizes): \n",
        "\n",
        "    ### compute flops for one forward pass on one datapoint\n",
        "    flops_ptflops, flops_fvcore, flops_pthflops, flops_profiler, num_params_fvcore = get_flops_forward_all_methods(model)\n",
        "\n",
        "    ### compute times for different batch_sizes\n",
        "    batch_sizes_time_dict = dict()\n",
        "    for batch_size in batch_sizes:\n",
        "\n",
        "        print(\"model: {}; batch_size: {};\".format(model_name, batch_size))\n",
        "        ### define training data\n",
        "        testloader = torch.utils.data.DataLoader(CIFAR10_testset, batch_size=batch_size,\n",
        "                                        shuffle=True, num_workers=1)\n",
        "\n",
        "        ### compute flops for one epoch an training time for a bunch of epochs\n",
        "        time_epoch = get_time_epoch_profiler(model, testloader)\n",
        "\n",
        "        batch_sizes_time_dict[batch_size] = time_epoch\n",
        "\n",
        "    ### save results for current batch size in dict\n",
        "    results = {\n",
        "        \"flops_ptflops_forward\":flops_ptflops,\n",
        "        \"flops_fvcore_forward\":flops_fvcore,\n",
        "        \"flops_pthflops_forward\":flops_pthflops,\n",
        "        \"flops_profiler_forward\":flops_profiler,\n",
        "        \"num_params\":num_params_fvcore,\n",
        "        \"time_epoch_batch_sizes\":batch_sizes_time_dict\n",
        "    }\n",
        "    print(results)\n",
        "\n",
        "    return(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z8tzoFdSkQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d35d1b-c6b5-4669-e89c-2a3672a41236"
      },
      "source": [
        "#batch_sizes_test = [256, 128, 64]\n",
        "#batch_sizes_test = [128, 64]\n",
        "batch_sizes_test = [64]\n",
        "#model, model_name = test_net, \"test_net\"\n",
        "#model, model_name = resnet18, \"resnet18\"\n",
        "#model, model_name = resnet34, \"resnet34\"\n",
        "#model, model_name = resnet50, \"resnet50\"\n",
        "#model, model_name = resnet101, \"resnet101\"\n",
        "#model, model_name = resnet152, \"resnet152\"\n",
        "#model, model_name = vgg11, \"vgg11\"\n",
        "#model, model_name = vgg13, \"vgg13\" \n",
        "#model, model_name = vgg16, \"vgg16\"\n",
        "#model, model_name = vgg19, \"vgg19\"\n",
        "#model, model_name = wide_resnet50_2, \"wide_resnet50_2\"\n",
        "#model, model_name = alexnet, \"alexnet\"\n",
        "#model, model_name = mobilenet_v2, \"mobilenet_v2\"\n",
        "model, model_name = efficientnet_b0, \"efficientnet_b0\"\n",
        "t0 = time.time()\n",
        "results_dict = compare_model_batch_sizes(model, model_name, batch_sizes_test)\n",
        "t1 = time.time()\n",
        "print(\"comparing models took {} seconds\".format(t1 - t0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsupported operator aten::silu_ encountered 49 time(s)\n",
            "Unsupported operator aten::sigmoid encountered 16 time(s)\n",
            "Unsupported operator aten::mul encountered 16 time(s)\n",
            "Unsupported operator aten::add_ encountered 9 time(s)\n",
            "Unsupported operator aten::dropout_ encountered 1 time(s)\n",
            "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "features.1.0.stochastic_depth, features.2.0.stochastic_depth, features.2.1.stochastic_depth, features.3.0.stochastic_depth, features.3.1.stochastic_depth, features.4.0.stochastic_depth, features.4.1.stochastic_depth, features.4.2.stochastic_depth, features.5.0.stochastic_depth, features.5.1.stochastic_depth, features.5.2.stochastic_depth, features.6.0.stochastic_depth, features.6.1.stochastic_depth, features.6.2.stochastic_depth, features.6.3.stochastic_depth, features.7.0.stochastic_depth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operation                      OPS        \n",
            "-----------------------------  ---------  \n",
            "features_0_0                   10838016   \n",
            "features_0_1                   802816     \n",
            "features_1_0_block_0_0         3612672    \n",
            "features_1_0_block_0_1         802816     \n",
            "features_1_0_block_1_avgpool   401408     \n",
            "features_1_0_block_1_fc1       264        \n",
            "features_1_0_block_1_fc2       288        \n",
            "mul                            802816     \n",
            "features_1_0_block_2_0         6422528    \n",
            "features_1_0_block_2_1         401408     \n",
            "features_2_0_block_0_0         19267584   \n",
            "features_2_0_block_0_1         2408448    \n",
            "features_2_0_block_1_0         2709504    \n",
            "features_2_0_block_1_1         602112     \n",
            "features_2_0_block_2_avgpool   301056     \n",
            "features_2_0_block_2_fc1       388        \n",
            "features_2_0_block_2_fc2       480        \n",
            "mul_1                          602112     \n",
            "features_2_0_block_3_0         7225344    \n",
            "features_2_0_block_3_1         150528     \n",
            "features_2_1_block_0_0         10838016   \n",
            "features_2_1_block_0_1         903168     \n",
            "features_2_1_block_1_0         4064256    \n",
            "features_2_1_block_1_1         903168     \n",
            "features_2_1_block_2_avgpool   451584     \n",
            "features_2_1_block_2_fc1       870        \n",
            "features_2_1_block_2_fc2       1008       \n",
            "mul_2                          903168     \n",
            "features_2_1_block_3_0         10838016   \n",
            "features_2_1_block_3_1         150528     \n",
            "add                            150528     \n",
            "features_3_0_block_0_0         10838016   \n",
            "features_3_0_block_0_1         903168     \n",
            "features_3_0_block_1_0         2822400    \n",
            "features_3_0_block_1_1         225792     \n",
            "features_3_0_block_2_avgpool   112896     \n",
            "features_3_0_block_2_fc1       870        \n",
            "features_3_0_block_2_fc2       1008       \n",
            "mul_3                          225792     \n",
            "features_3_0_block_3_0         4515840    \n",
            "features_3_0_block_3_1         62720      \n",
            "features_3_1_block_0_0         7526400    \n",
            "features_3_1_block_0_1         376320     \n",
            "features_3_1_block_1_0         4704000    \n",
            "features_3_1_block_1_1         376320     \n",
            "features_3_1_block_2_avgpool   188160     \n",
            "features_3_1_block_2_fc1       2410       \n",
            "features_3_1_block_2_fc2       2640       \n",
            "mul_4                          376320     \n",
            "features_3_1_block_3_0         7526400    \n",
            "features_3_1_block_3_1         62720      \n",
            "add_1                          62720      \n",
            "features_4_0_block_0_0         7526400    \n",
            "features_4_0_block_0_1         376320     \n",
            "features_4_0_block_1_0         423360     \n",
            "features_4_0_block_1_1         94080      \n",
            "features_4_0_block_2_avgpool   47040      \n",
            "features_4_0_block_2_fc1       2410       \n",
            "features_4_0_block_2_fc2       2640       \n",
            "mul_5                          94080      \n",
            "features_4_0_block_3_0         3763200    \n",
            "features_4_0_block_3_1         31360      \n",
            "features_4_1_block_0_0         7526400    \n",
            "features_4_1_block_0_1         188160     \n",
            "features_4_1_block_1_0         846720     \n",
            "features_4_1_block_1_1         188160     \n",
            "features_4_1_block_2_avgpool   94080      \n",
            "features_4_1_block_2_fc1       9620       \n",
            "features_4_1_block_2_fc2       10080      \n",
            "mul_6                          188160     \n",
            "features_4_1_block_3_0         7526400    \n",
            "features_4_1_block_3_1         31360      \n",
            "add_2                          31360      \n",
            "features_4_2_block_0_0         7526400    \n",
            "features_4_2_block_0_1         188160     \n",
            "features_4_2_block_1_0         846720     \n",
            "features_4_2_block_1_1         188160     \n",
            "features_4_2_block_2_avgpool   94080      \n",
            "features_4_2_block_2_fc1       9620       \n",
            "features_4_2_block_2_fc2       10080      \n",
            "mul_7                          188160     \n",
            "features_4_2_block_3_0         7526400    \n",
            "features_4_2_block_3_1         31360      \n",
            "add_3                          31360      \n",
            "features_5_0_block_0_0         7526400    \n",
            "features_5_0_block_0_1         188160     \n",
            "features_5_0_block_1_0         2352000    \n",
            "features_5_0_block_1_1         188160     \n",
            "features_5_0_block_2_avgpool   94080      \n",
            "features_5_0_block_2_fc1       9620       \n",
            "features_5_0_block_2_fc2       10080      \n",
            "mul_8                          188160     \n",
            "features_5_0_block_3_0         10536960   \n",
            "features_5_0_block_3_1         43904      \n",
            "features_5_1_block_0_0         14751744   \n",
            "features_5_1_block_0_1         263424     \n",
            "features_5_1_block_1_0         3292800    \n",
            "features_5_1_block_1_1         263424     \n",
            "features_5_1_block_2_avgpool   131712     \n",
            "features_5_1_block_2_fc1       18844      \n",
            "features_5_1_block_2_fc2       19488      \n",
            "mul_9                          263424     \n",
            "features_5_1_block_3_0         14751744   \n",
            "features_5_1_block_3_1         43904      \n",
            "add_4                          43904      \n",
            "features_5_2_block_0_0         14751744   \n",
            "features_5_2_block_0_1         263424     \n",
            "features_5_2_block_1_0         3292800    \n",
            "features_5_2_block_1_1         263424     \n",
            "features_5_2_block_2_avgpool   131712     \n",
            "features_5_2_block_2_fc1       18844      \n",
            "features_5_2_block_2_fc2       19488      \n",
            "mul_10                         263424     \n",
            "features_5_2_block_3_0         14751744   \n",
            "features_5_2_block_3_1         43904      \n",
            "add_5                          43904      \n",
            "features_6_0_block_0_0         14751744   \n",
            "features_6_0_block_0_1         263424     \n",
            "features_6_0_block_1_0         823200     \n",
            "features_6_0_block_1_1         65856      \n",
            "features_6_0_block_2_avgpool   32928      \n",
            "features_6_0_block_2_fc1       18844      \n",
            "features_6_0_block_2_fc2       19488      \n",
            "mul_11                         65856      \n",
            "features_6_0_block_3_0         6322176    \n",
            "features_6_0_block_3_1         18816      \n",
            "features_6_1_block_0_0         10838016   \n",
            "features_6_1_block_0_1         112896     \n",
            "features_6_1_block_1_0         1411200    \n",
            "features_6_1_block_1_1         112896     \n",
            "features_6_1_block_2_avgpool   56448      \n",
            "features_6_1_block_2_fc1       55344      \n",
            "features_6_1_block_2_fc2       56448      \n",
            "mul_12                         112896     \n",
            "features_6_1_block_3_0         10838016   \n",
            "features_6_1_block_3_1         18816      \n",
            "add_6                          18816      \n",
            "features_6_2_block_0_0         10838016   \n",
            "features_6_2_block_0_1         112896     \n",
            "features_6_2_block_1_0         1411200    \n",
            "features_6_2_block_1_1         112896     \n",
            "features_6_2_block_2_avgpool   56448      \n",
            "features_6_2_block_2_fc1       55344      \n",
            "features_6_2_block_2_fc2       56448      \n",
            "mul_13                         112896     \n",
            "features_6_2_block_3_0         10838016   \n",
            "features_6_2_block_3_1         18816      \n",
            "add_7                          18816      \n",
            "features_6_3_block_0_0         10838016   \n",
            "features_6_3_block_0_1         112896     \n",
            "features_6_3_block_1_0         1411200    \n",
            "features_6_3_block_1_1         112896     \n",
            "features_6_3_block_2_avgpool   56448      \n",
            "features_6_3_block_2_fc1       55344      \n",
            "features_6_3_block_2_fc2       56448      \n",
            "mul_14                         112896     \n",
            "features_6_3_block_3_0         10838016   \n",
            "features_6_3_block_3_1         18816      \n",
            "add_8                          18816      \n",
            "features_7_0_block_0_0         10838016   \n",
            "features_7_0_block_0_1         112896     \n",
            "features_7_0_block_1_0         508032     \n",
            "features_7_0_block_1_1         112896     \n",
            "features_7_0_block_2_avgpool   56448      \n",
            "features_7_0_block_2_fc1       55344      \n",
            "features_7_0_block_2_fc2       56448      \n",
            "mul_15                         112896     \n",
            "features_7_0_block_3_0         18063360   \n",
            "features_7_0_block_3_1         31360      \n",
            "features_8_0                   20070400   \n",
            "features_8_1                   125440     \n",
            "avgpool                        62720      \n",
            "classifier_1                   12810      \n",
            "----------------------------   --------   \n",
            "Input size: (1, 3, 224, 224)\n",
            "405,434,822 FLOPs or approx. 0.41 GFLOPs\n",
            "model: efficientnet_b0; batch_size: 64;\n",
            "measure time\n",
            "{'flops_ptflops_forward': 400401542.0, 'flops_fvcore_forward': 400392192, 'flops_pthflops_forward': 405434822, 'flops_profiler_forward': 384552032.0, 'num_params': 4020358, 'time_epoch_batch_sizes': {64: 33753356}}\n",
            "comparing models took 145.1234471797943 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtIGQoTB9z7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04afdd85-da4d-44b7-a448-21677b437921"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 19 17:46:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    39W / 250W |  10693MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cBXG2hvbl2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f566cc-8489-4217-b852-a349c873c133"
      },
      "source": [
        "results_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flops_fvcore_forward': 400392192,\n",
              " 'flops_profiler_forward': 384552032.0,\n",
              " 'flops_ptflops_forward': 400401542.0,\n",
              " 'flops_pthflops_forward': 405434822,\n",
              " 'num_params': 4020358,\n",
              " 'time_epoch_batch_sizes': {64: 33753356}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp7szhwf-65C"
      },
      "source": [
        "### don't forget to name the GPU that you were using and the right model class (e.g. resnets)\n",
        "GPU_type = \"Tesla_P100\"\n",
        "results_dict['GPU_type'] = GPU_type\n",
        "torch.save(results_dict, data_file_location + \"{}_flops_time_{}.pt\".format(model_name, GPU_type))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqh29__2rn99"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}