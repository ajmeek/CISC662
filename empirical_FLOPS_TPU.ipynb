{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f8c05610a3044998370a209c88571dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2388ae3dd4f64399987b8a2a3ca6394e",
              "IPY_MODEL_3c3c7c0dde2c4c1ba56875515f54410f",
              "IPY_MODEL_1cf7c8ac4b1b42f192f6f08f5de02786"
            ],
            "layout": "IPY_MODEL_56e57671a8f643d0b2cd6a7523f79ce0"
          }
        },
        "2388ae3dd4f64399987b8a2a3ca6394e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_043e87c6e96b4f38829c444835625f22",
            "placeholder": "​",
            "style": "IPY_MODEL_31a13889332248bd8627f7c408996b2a",
            "value": "100%"
          }
        },
        "3c3c7c0dde2c4c1ba56875515f54410f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_603bb718de764e3eba01a49b9af5191e",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2c368c6046946eb97e0818d7c83a2c9",
            "value": 170498071
          }
        },
        "1cf7c8ac4b1b42f192f6f08f5de02786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d4e8d9d92ca4af4bab1336081d30252",
            "placeholder": "​",
            "style": "IPY_MODEL_cfaba97ccb0b4faf88e62b0869e0aebf",
            "value": " 170498071/170498071 [00:14&lt;00:00, 13794355.52it/s]"
          }
        },
        "56e57671a8f643d0b2cd6a7523f79ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "043e87c6e96b4f38829c444835625f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31a13889332248bd8627f7c408996b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "603bb718de764e3eba01a49b9af5191e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c368c6046946eb97e0818d7c83a2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d4e8d9d92ca4af4bab1336081d30252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfaba97ccb0b4faf88e62b0869e0aebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameek2/CISC662/blob/master/empirical_FLOPS_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook adapted from Marius Hobbhahn, link: https://www.lesswrong.com/posts/jJApGWG95495pYM7C/how-to-measure-flop-s-for-neural-networks-empirically\n",
        "\n",
        "We are adapting this code to run on both GPU and TPUs to determine NN utilization for analysis in roofline models. This is for a project for our Computer Architecture class (CISC 662 at the University of Delaware)."
      ],
      "metadata": {
        "id": "q6c_g8u6NPhT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW5v_WhOERqz"
      },
      "source": [
        "### Measuring FLOPS in Pytorch\n",
        "\n",
        "To test FLOPS/s for currently used ML models we train multiple different classic NN architectures by training them for 10 epochs on CIFAR10.\n",
        "\n",
        "By reconnecting our Colab instance a bunch of times, we will try to get different GPUs to make the process comparable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQnW0HP5D2dc",
        "outputId": "c8ecd1e2-cb63-4835-bab1-3ac34cfe490a"
      },
      "source": [
        "### set up google files\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) \n",
        "\n",
        "file_location = '/content/drive/My Drive/Parameters, Compute and Data Trends in Machine Learning/empirical_FLOPs/'\n",
        "data_file_location = file_location + 'data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFkpuIKYEMmy",
        "outputId": "d4c121d1-fec9-438b-8884-93e5a401d24c"
      },
      "source": [
        "!nvidia-smi\n",
        "#Tesla P100-PCIE... (Austin note: when we use a GPU accelerator, it may be a P100 or a T4)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgHriJayMGTE",
        "outputId": "2c64c230-4dd4-4353-f5fb-3c1d586eb11e"
      },
      "source": [
        "!pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git\n",
        "!pip install -U 'git+https://github.com/facebookresearch/fvcore'\n",
        "!pip install onnx -U\n",
        "!pip install fprint\n",
        "!pip install pthflops -U\n",
        "!pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/sovrasov/flops-counter.pytorch.git\n",
            "  Cloning https://github.com/sovrasov/flops-counter.pytorch.git to /tmp/pip-req-build-axfcg71e\n",
            "  Running command git clone -q https://github.com/sovrasov/flops-counter.pytorch.git /tmp/pip-req-build-axfcg71e\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from ptflops==0.6.9) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->ptflops==0.6.9) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/fvcore\n",
            "  Cloning https://github.com/facebookresearch/fvcore to /tmp/pip-req-build-tifn8zur\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore /tmp/pip-req-build-tifn8zur\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore==0.1.5) (1.21.6)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from fvcore==0.1.5) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore==0.1.5) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore==0.1.5) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore==0.1.5) (2.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore==0.1.5) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore==0.1.5) (0.8.10)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from fvcore==0.1.5) (0.1.10)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath>=0.1.7->fvcore==0.1.5) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from iopath>=0.1.7->fvcore==0.1.5) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.8/dist-packages (1.12.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from onnx) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fprint in /usr/local/lib/python3.8/dist-packages (1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pthflops in /usr/local/lib/python3.8/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pthflops) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pthflops) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/Lyken17/pytorch-OpCounter.git\n",
            "  Cloning https://github.com/Lyken17/pytorch-OpCounter.git to /tmp/pip-req-build-ihffo69z\n",
            "  Running command git clone -q https://github.com/Lyken17/pytorch-OpCounter.git /tmp/pip-req-build-ihffo69z\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from thop==0.1.1-2212010102) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->thop==0.1.1-2212010102) (4.1.1)\n",
            "Building wheels for collected packages: thop\n",
            "  Building wheel for thop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thop: filename=thop-0.1.1.post2212010102-py3-none-any.whl size=15462 sha256=5320b73a88ac0524a67b6edd52bd91211495390e350d41f42d97beed87c495a7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-13eoa0zr/wheels/0e/09/14/1e8332ef67248a9e3a4788150f079ce25a46a43af425f322c9\n",
            "Successfully built thop\n",
            "Installing collected packages: thop\n",
            "  Attempting uninstall: thop\n",
            "    Found existing installation: thop 0.1.1.post2212010101\n",
            "    Uninstalling thop-0.1.1.post2212010101:\n",
            "      Successfully uninstalled thop-0.1.1.post2212010101\n",
            "Successfully installed thop-0.1.1.post2212010102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "496-iLzWEzUN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "e86dc792-3064-4759-f0cc-4f18797a4a91"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "#for working with TPUs\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cafd61cf0c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#for working with TPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_xla/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WRONG PACKAGE. Please install the package from Neuron Repository - pip.repos.neuron.amazonaws.com\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: WRONG PACKAGE. Please install the package from Neuron Repository - pip.repos.neuron.amazonaws.com",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3f8c05610a3044998370a209c88571dd",
            "2388ae3dd4f64399987b8a2a3ca6394e",
            "3c3c7c0dde2c4c1ba56875515f54410f",
            "1cf7c8ac4b1b42f192f6f08f5de02786",
            "56e57671a8f643d0b2cd6a7523f79ce0",
            "043e87c6e96b4f38829c444835625f22",
            "31a13889332248bd8627f7c408996b2a",
            "603bb718de764e3eba01a49b9af5191e",
            "c2c368c6046946eb97e0818d7c83a2c9",
            "4d4e8d9d92ca4af4bab1336081d30252",
            "cfaba97ccb0b4faf88e62b0869e0aebf"
          ]
        },
        "id": "_f2nJxbuE42Q",
        "outputId": "3eaf7dc1-3e87-4c61-e5ad-da82a1a23591"
      },
      "source": [
        "### import dataset\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "batch_size_default = 128\n",
        "\n",
        "CIFAR10_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "CIFAR10_testloader = torch.utils.data.DataLoader(CIFAR10_testset, batch_size=batch_size_default,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f8c05610a3044998370a209c88571dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ii-HlAoE-QX"
      },
      "source": [
        "### import different models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TestNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 5, 10)\n",
        "        self.conv2 = nn.Conv2d(5, 6, 10)\n",
        "        self.fc1 = nn.Linear(254616, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "test_net = TestNet().cuda()\n",
        "\n",
        "resnet18 = models.resnet18(num_classes=10).cuda()\n",
        "resnet34 = models.resnet34(num_classes=10).cuda()\n",
        "resnet50 = models.resnet50(num_classes=10).cuda()\n",
        "resnet101 = models.resnet101(num_classes=10).cuda()\n",
        "resnet152 = models.resnet152(num_classes=10).cuda()\n",
        "\n",
        "vgg11 = models.vgg11(num_classes=10).cuda()\n",
        "vgg13 = models.vgg13(num_classes=10).cuda()\n",
        "vgg16 = models.vgg16(num_classes=10).cuda()\n",
        "vgg19 = models.vgg19(num_classes=10).cuda()\n",
        "\n",
        "wide_resnet50_2 = models.wide_resnet50_2(num_classes=10).cuda()\n",
        "alexnet = models.alexnet(num_classes=10).cuda()\n",
        "mobilenet_v2 = models.mobilenet_v2(num_classes=10).cuda()\n",
        "efficientnet_b0 = models.efficientnet_b0(num_classes=10).cuda()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Krj8YWMALH"
      },
      "source": [
        "### set up flop counting libraries\n",
        "import ptflops\n",
        "import fvcore\n",
        "from pthflops import count_ops#\n",
        "from ptflops import get_model_complexity_info\n",
        "from fvcore.nn import FlopCountAnalysis, parameter_count\n",
        "from thop.profile import profile as thop_profile\n",
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKXBPINSrL46",
        "outputId": "af3fabf6-1890-4139-90b6-c50ab40473c1"
      },
      "source": [
        "# using fvcore\n",
        "def get_flops_fvcore_per_layer(model, inputs=(torch.randn((1,3,224,224)).cuda(),)):\n",
        "\n",
        "    FMAs_per_layer = FlopCountAnalysis(model, inputs).by_module_and_operator()\n",
        "    return(FMAs_per_layer)\n",
        "\n",
        "def get_flops_ptflops_per_layer(model, input_dims=(3, 224, 224)):\n",
        "\n",
        "    with torch.cuda.device(0):\n",
        "        FMAs, _ = get_model_complexity_info(model, input_dims, as_strings=False,\n",
        "                                            print_per_layer_stat=True, verbose=False)\n",
        "    return(FMAs, _)\n",
        "\n",
        "print(get_flops_fvcore_per_layer(vgg13, inputs=(torch.randn((1,3,224,224)).cuda(),)))\n",
        "print(get_flops_ptflops_per_layer(vgg13, input_dims=(3, 224, 224)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 5 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': Counter({'conv': 11184832512, 'linear': 119578624, 'adaptive_avg_pool2d': 25088}), 'features': Counter({'conv': 11184832512}), 'features.0': Counter({'conv': 86704128}), 'features.1': Counter(), 'features.2': Counter({'conv': 1849688064}), 'features.3': Counter(), 'features.4': Counter(), 'features.5': Counter({'conv': 924844032}), 'features.6': Counter(), 'features.7': Counter({'conv': 1849688064}), 'features.8': Counter(), 'features.9': Counter(), 'features.10': Counter({'conv': 924844032}), 'features.11': Counter(), 'features.12': Counter({'conv': 1849688064}), 'features.13': Counter(), 'features.14': Counter(), 'features.15': Counter({'conv': 924844032}), 'features.16': Counter(), 'features.17': Counter({'conv': 1849688064}), 'features.18': Counter(), 'features.19': Counter(), 'features.20': Counter({'conv': 462422016}), 'features.21': Counter(), 'features.22': Counter({'conv': 462422016}), 'features.23': Counter(), 'features.24': Counter(), 'avgpool': Counter({'adaptive_avg_pool2d': 25088}), 'classifier': Counter({'linear': 119578624}), 'classifier.0': Counter({'linear': 102760448}), 'classifier.1': Counter(), 'classifier.2': Counter(), 'classifier.3': Counter({'linear': 16777216}), 'classifier.4': Counter(), 'classifier.5': Counter(), 'classifier.6': Counter({'linear': 40960})}\n",
            "VGG(\n",
            "  128.99 M, 100.000% Params, 11.34 GMac, 100.000% MACs, \n",
            "  (features): Sequential(\n",
            "    9.4 M, 7.291% Params, 11.22 GMac, 98.945% MACs, \n",
            "    (0): Conv2d(1.79 k, 0.001% Params, 89.92 MMac, 0.793% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(0, 0.000% Params, 3.21 MMac, 0.028% MACs, inplace=True)\n",
            "    (2): Conv2d(36.93 k, 0.029% Params, 1.85 GMac, 16.347% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(0, 0.000% Params, 3.21 MMac, 0.028% MACs, inplace=True)\n",
            "    (4): MaxPool2d(0, 0.000% Params, 3.21 MMac, 0.028% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(73.86 k, 0.057% Params, 926.45 MMac, 8.173% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(0, 0.000% Params, 1.61 MMac, 0.014% MACs, inplace=True)\n",
            "    (7): Conv2d(147.58 k, 0.114% Params, 1.85 GMac, 16.332% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(0, 0.000% Params, 1.61 MMac, 0.014% MACs, inplace=True)\n",
            "    (9): MaxPool2d(0, 0.000% Params, 1.61 MMac, 0.014% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(295.17 k, 0.229% Params, 925.65 MMac, 8.166% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)\n",
            "    (12): Conv2d(590.08 k, 0.457% Params, 1.85 GMac, 16.325% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)\n",
            "    (14): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(1.18 M, 0.915% Params, 925.25 MMac, 8.163% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): ReLU(0, 0.000% Params, 401.41 KMac, 0.004% MACs, inplace=True)\n",
            "    (17): Conv2d(2.36 M, 1.829% Params, 1.85 GMac, 16.322% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(0, 0.000% Params, 401.41 KMac, 0.004% MACs, inplace=True)\n",
            "    (19): MaxPool2d(0, 0.000% Params, 401.41 KMac, 0.004% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (20): Conv2d(2.36 M, 1.829% Params, 462.52 MMac, 4.080% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): ReLU(0, 0.000% Params, 100.35 KMac, 0.001% MACs, inplace=True)\n",
            "    (22): Conv2d(2.36 M, 1.829% Params, 462.52 MMac, 4.080% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): ReLU(0, 0.000% Params, 100.35 KMac, 0.001% MACs, inplace=True)\n",
            "    (24): MaxPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 25.09 KMac, 0.000% MACs, output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    119.59 M, 92.709% Params, 119.6 MMac, 1.055% MACs, \n",
            "    (0): Linear(102.76 M, 79.667% Params, 102.76 MMac, 0.907% MACs, in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(0, 0.000% Params, 4.1 KMac, 0.000% MACs, inplace=True)\n",
            "    (2): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (3): Linear(16.78 M, 13.010% Params, 16.78 MMac, 0.148% MACs, in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(0, 0.000% Params, 4.1 KMac, 0.000% MACs, inplace=True)\n",
            "    (5): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (6): Linear(40.97 k, 0.032% Params, 40.97 KMac, 0.000% MACs, in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "(11335059978.0, 128991818)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnN6C-mzb2cy"
      },
      "source": [
        "### returns the flops and number of parameters of a model\n",
        "# using ptflops\n",
        "def get_flops_ptflops(model, input_dims=(3, 224, 224)):\n",
        "\n",
        "    with torch.cuda.device(0):\n",
        "        macs, num_params = get_model_complexity_info(model, input_dims, as_strings=False,\n",
        "                                            print_per_layer_stat=False, verbose=False)\n",
        "    return(macs, num_params)\n",
        "\n",
        "# using fvcore\n",
        "def get_flops_fvcore(model, inputs=(torch.randn((1,3,224,224)),)):\n",
        "\n",
        "    flops = FlopCountAnalysis(model, inputs)\n",
        "    total_flops = flops.total()\n",
        "    num_params = parameter_count(model)['']\n",
        "    return(total_flops, num_params)\n",
        "\n",
        "# using thop\n",
        "def get_flops_thop(model, inputs=(torch.randn((1,3,224,224)),)):\n",
        "\n",
        "    macs, params = thop_profile(model, inputs=inputs)\n",
        "    return(macs, params)\n",
        "\n",
        "# using pthflops\n",
        "def get_flops_pthflops(model, inputs=torch.randn(1,3,224,224)):\n",
        "\n",
        "    flops = count_ops(model, inputs)\n",
        "    return(flops[0])\n",
        "\n",
        "\n",
        "# using the profiler\n",
        "def get_flops_profiler_old(model, inputs=(torch.randn((1,3,224,224)),)):\n",
        "\n",
        "    with profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ],\n",
        "        with_flops=True) as prof:\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "\n",
        "    events = prof.events()\n",
        "    flops = sum([int(evt.flops) for evt in events]) \n",
        "    flops = flops / 2 # divide by 2 because of FMAs (see text)\n",
        "    return(flops)\n",
        "\n",
        "    # using the profiler\n",
        "def get_flops_profiler(model, inputs=(torch.randn((1,3,224,224)),)):\n",
        "\n",
        "    # warm up cuda memory allocator, recommended here: https://github.com/pytorch/pytorch/blob/master/torch/autograd/profiler.py\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    with torch.profiler.profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ],\n",
        "        with_flops=True) as prof:\n",
        "            with record_function(\"model_inference\"):\n",
        "                outputs = model(inputs)\n",
        "\n",
        "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
        "    events = prof.events()\n",
        "    flops = sum([int(evt.flops) for evt in events]) \n",
        "    flops = flops / 2 # divide by 2 because of FMAs (see text)\n",
        "    return(flops)\n",
        "\n",
        "def get_flops_profiler_bw(model, inputs=(torch.randn((1,3,224,224)),), y=torch.tensor([0]).cuda()):\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    # warm up cuda memory allocator, recommended here: https://github.com/pytorch/pytorch/blob/master/torch/autograd/profiler.py\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    ### measure only backward pass\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    with torch.profiler.profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ],\n",
        "        with_flops=True) as prof:\n",
        "            with record_function(\"model_inference\"):\n",
        "                loss = criterion(outputs, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "\n",
        "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
        "    events = prof.events()\n",
        "    flops = sum([int(evt.flops) for evt in events]) \n",
        "    flops = flops / 2 # divide by 2 because of FMAs (see text)\n",
        "    return(flops)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFN5a2gaZavt",
        "outputId": "92c55433-089c-45fe-b773-ebf6a44fa342"
      },
      "source": [
        "#flops_profiler = get_flops_profiler(resnet18, inputs=torch.randn((1,3,224,224)).cuda())\n",
        "#print(\"profiler: \", flops_profiler)\n",
        "\n",
        "flops_profiler = get_flops_profiler_bw(resnet18, inputs=torch.randn((1,3,224,224)).cuda())\n",
        "print(\"profiler: \", flops_profiler)\n",
        "### doesn't seem to measure the backward pass ... "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  Total KFLOPs  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         1.21%     359.000us        14.19%       4.203ms     210.150us       0.000us         0.00%       6.231ms     311.550us            20            --  \n",
            "                                   ConvolutionBackward0         0.57%     169.000us        12.38%       3.669ms     183.450us       0.000us         0.00%       6.165ms     308.250us            20            --  \n",
            "                             aten::convolution_backward         8.51%       2.522ms        11.81%       3.500ms     175.000us       6.165ms        70.62%       6.165ms     308.250us            20            --  \n",
            "void cudnn::cnn::wgrad_alg1_engine<float, float, 128...         0.00%       0.000us         0.00%       0.000us       0.000us       1.649ms        18.89%       1.649ms     183.222us             9            --  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.580ms        18.10%       1.580ms      11.970us           132            --  \n",
            "                                             aten::add_         2.92%     865.000us         5.25%       1.555ms      12.540us       1.514ms        17.34%       1.514ms      12.210us           124            --  \n",
            "void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3...         0.00%       0.000us         0.00%       0.000us       0.000us       1.230ms        14.09%       1.230ms     175.714us             7            --  \n",
            "volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148...         0.00%       0.000us         0.00%       0.000us       0.000us       1.163ms        13.32%       1.163ms     116.300us            10            --  \n",
            "                                        model_inference        46.66%      13.824ms        64.55%      19.123ms      19.123ms       0.000us         0.00%     792.000us     792.000us             1            --  \n",
            "                                Optimizer.step#SGD.step         1.36%     402.000us         3.48%       1.030ms       1.030ms       0.000us         0.00%     777.000us     777.000us             1            --  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 29.625ms\n",
            "Self CUDA time total: 8.730ms\n",
            "\n",
            "profiler:  474368.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2AuVIi0xyls",
        "outputId": "bfce6fdb-ccd3-42e2-8b89-cf361df81f67"
      },
      "source": [
        "def get_flops_profiler_full_table(model, inputs=torch.randn(1,3,224,224).cuda()):\n",
        "\n",
        "    # warm up cuda memory allocator, recommended here: https://github.com/pytorch/pytorch/blob/master/torch/autograd/profiler.py\n",
        "    #outputs = model(inputs)\n",
        "\n",
        "    with torch.profiler.profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ],\n",
        "        with_flops=True) as prof:\n",
        "            with record_function(\"model_inference\"):\n",
        "                outputs = model(inputs)\n",
        "\n",
        "    print(prof.key_averages().table(row_limit=1000))\n",
        "    #print(prof.events())\n",
        "    events = prof.events()\n",
        "    flops = sum([int(evt.flops) for evt in events]) \n",
        "    flops = flops / 2 # divide by 2 because of FMAs (see text)\n",
        "    return(flops)\n",
        "\n",
        "get_flops_profiler_full_table(alexnet, inputs=torch.randn(1,3,224,224).cuda())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  Total MFLOPs  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::zeros         0.30%      20.000us         0.46%      30.000us      30.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "                                            aten::empty         1.82%     120.000us         1.82%     120.000us      15.000us       0.000us         0.00%       0.000us       0.000us             8            --  \n",
            "                                            aten::zero_         0.05%       3.000us         0.05%       3.000us       3.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "                                        model_inference        13.67%     900.000us        97.46%       6.415ms       6.415ms       0.000us         0.00%       2.166ms       2.166ms             1            --  \n",
            "                                           aten::conv2d         0.53%      35.000us        62.49%       4.113ms     822.600us       0.000us         0.00%       1.222ms     244.400us             5      1311.133  \n",
            "                                      aten::convolution         1.41%      93.000us        61.96%       4.078ms     815.600us       0.000us         0.00%       1.222ms     244.400us             5            --  \n",
            "                                     aten::_convolution         1.67%     110.000us        60.54%       3.985ms     797.000us       0.000us         0.00%       1.222ms     244.400us             5            --  \n",
            "                                aten::cudnn_convolution        50.18%       3.303ms        55.07%       3.625ms     725.000us       1.184ms        54.66%       1.184ms     236.800us             5            --  \n",
            "                                  cudaStreamIsCapturing         0.15%      10.000us         0.15%      10.000us       1.429us       0.000us         0.00%       0.000us       0.000us             7            --  \n",
            "                                  cudaStreamGetPriority         0.02%       1.000us         0.02%       1.000us       0.200us       0.000us         0.00%       0.000us       0.000us             5            --  \n",
            "                       cudaDeviceGetStreamPriorityRange         0.06%       4.000us         0.06%       4.000us       0.800us       0.000us         0.00%       0.000us       0.000us             5            --  \n",
            "                                       cudaLaunchKernel         8.61%     567.000us         8.61%     567.000us      17.719us       0.000us         0.00%       0.000us       0.000us            32            --  \n",
            "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us       9.000us         0.42%       9.000us       4.500us             2            --  \n",
            "             volta_scudnn_128x64_relu_xregs_large_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     125.000us         5.77%     125.000us     125.000us             1            --  \n",
            "                                          aten::reshape         0.38%      25.000us         0.59%      39.000us       7.800us       0.000us         0.00%       0.000us       0.000us             5            --  \n",
            "                                   aten::_reshape_alias         0.44%      29.000us         0.44%      29.000us       4.833us       0.000us         0.00%       0.000us       0.000us             6            --  \n",
            "                                             aten::add_         2.05%     135.000us         3.21%     211.000us      42.200us      38.000us         1.75%      38.000us       7.600us             5            --  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      38.000us         1.75%      38.000us       7.600us             5            --  \n",
            "                                            aten::relu_         2.20%     145.000us         5.80%     382.000us      54.571us       0.000us         0.00%      36.000us       5.143us             7            --  \n",
            "                                       aten::clamp_min_         1.87%     123.000us         3.60%     237.000us      33.857us      36.000us         1.66%      36.000us       5.143us             7            --  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      36.000us         1.66%      36.000us       5.143us             7            --  \n",
            "                                       aten::max_pool2d         0.21%      14.000us         2.64%     174.000us      58.000us       0.000us         0.00%      31.000us      10.333us             3            --  \n",
            "                          aten::max_pool2d_with_indices         1.73%     114.000us         2.43%     160.000us      53.333us      31.000us         1.43%      31.000us      10.333us             3            --  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us      31.000us         1.43%      31.000us      10.333us             3            --  \n",
            "                   volta_scudnn_128x64_relu_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     435.000us        20.08%     435.000us     435.000us             1            --  \n",
            "void cudnn::winograd::generateWinogradTilesKernel<0,...         0.00%       0.000us         0.00%       0.000us       0.000us     109.000us         5.03%     109.000us      36.333us             3            --  \n",
            "volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148...         0.00%       0.000us         0.00%       0.000us       0.000us     506.000us        23.36%     506.000us     168.667us             3            --  \n",
            "                              aten::adaptive_avg_pool2d         0.08%       5.000us         1.11%      73.000us      73.000us       0.000us         0.00%      14.000us      14.000us             1            --  \n",
            "                             aten::_adaptive_avg_pool2d         0.43%      28.000us         1.03%      68.000us      68.000us      14.000us         0.65%      14.000us      14.000us             1            --  \n",
            "                                          aten::resize_         0.20%      13.000us         0.20%      13.000us      13.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "void at::native::(anonymous namespace)::adaptive_ave...         0.00%       0.000us         0.00%       0.000us       0.000us      14.000us         0.65%      14.000us      14.000us             1            --  \n",
            "                                          aten::flatten         0.09%       6.000us         0.32%      21.000us      21.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "                                          aten::dropout         0.17%      11.000us         3.19%     210.000us     105.000us       0.000us         0.00%      12.000us       6.000us             2            --  \n",
            "                                   aten::native_dropout         1.41%      93.000us         3.02%     199.000us      99.500us      12.000us         0.55%      12.000us       6.000us             2            --  \n",
            "                                       aten::empty_like         0.23%      15.000us         0.82%      54.000us      13.500us       0.000us         0.00%       0.000us       0.000us             4            --  \n",
            "                                    aten::empty_strided         0.59%      39.000us         0.59%      39.000us       9.750us       0.000us         0.00%       0.000us       0.000us             4            --  \n",
            "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      12.000us         0.55%      12.000us       6.000us             2            --  \n",
            "                                           aten::linear         0.77%      51.000us         8.19%     539.000us     179.667us       0.000us         0.00%     851.000us     283.667us             3            --  \n",
            "                                                aten::t         0.47%      31.000us         0.82%      54.000us      18.000us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                                        aten::transpose         0.24%      16.000us         0.35%      23.000us       7.667us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                                       aten::as_strided         0.41%      27.000us         0.41%      27.000us       4.500us       0.000us         0.00%       0.000us       0.000us             6            --  \n",
            "                                            aten::addmm         3.62%     238.000us         6.59%     434.000us     144.667us     851.000us        39.29%     851.000us     283.667us             3       109.134  \n",
            "                                           aten::expand         0.15%      10.000us         0.46%      30.000us      10.000us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                                        cudaMemcpyAsync         1.37%      90.000us         1.37%      90.000us      30.000us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      12.000us         0.55%      12.000us       4.000us             3            --  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.18%      12.000us         0.18%      12.000us       4.000us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us     573.000us        26.45%     573.000us     573.000us             1            --  \n",
            "                               cudaStreamGetCaptureInfo         0.05%       3.000us         0.05%       3.000us       1.000us       0.000us         0.00%       0.000us       0.000us             3            --  \n",
            "                                         cudaEventQuery         0.09%       6.000us         0.09%       6.000us       6.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us     254.000us        11.73%     254.000us     254.000us             1            --  \n",
            "                                  cudaDeviceSynchronize         2.08%     137.000us         2.08%     137.000us     137.000us       0.000us         0.00%       0.000us       0.000us             1            --  \n",
            "void dot_kernel<float, 128, 0, cublasDotParams<cubla...         0.00%       0.000us         0.00%       0.000us       0.000us       7.000us         0.32%       7.000us       7.000us             1            --  \n",
            "void reduce_1Block_kernel<float, 128, 7, cublasGemvT...         0.00%       0.000us         0.00%       0.000us       0.000us       5.000us         0.23%       5.000us       5.000us             1            --  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 6.582ms\n",
            "Self CUDA time total: 2.166ms\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "710133440.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvP9WFhExmBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b84864e-68c2-4655-feb2-bfd1d2213180"
      },
      "source": [
        "### test for TestNet\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(test_net, input_dims=(3, 224, 224))\n",
        "print(\"ptflops: \", flops_ptflops, \"num_params: \", num_params_ptflops)\n",
        "\n",
        "flops_fvcore, num_params_fvcore = get_flops_fvcore(test_net, inputs=(torch.randn((1,3,224,224)).cuda(),))\n",
        "print(\"fvcore: \", flops_fvcore, \"num_params: \", num_params_fvcore)\n",
        "\n",
        "#flops_thop, num_params_thop = get_flops_thop(test_net, inputs=(torch.randn((1,3,224,224)),))\n",
        "#print(\"thop: \", flops_thop, \"num_params: \", num_params_thop)\n",
        "# some problem with fprint\n",
        "\n",
        "flops_pthflops = get_flops_pthflops(test_net, inputs=torch.randn(1,3,224,224).cuda())\n",
        "print(\"pthflops: \", flops_pthflops)\n",
        "\n",
        "flops_profiler = get_flops_profiler(test_net, inputs=torch.randn((1,3,224,224)).cuda())\n",
        "print(\"profiler: \", flops_profiler)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptflops:  199677411.0 num_params:  2550681\n",
            "fvcore:  199191660 num_params:  2550681\n",
            "OperationOPS         \n",
            "------  ----------  \n",
            "conv1   69568625    \n",
            "conv2   127562616   \n",
            "fc1     2546170     \n",
            "-----   ---------   \n",
            "Input size: (1, 3, 224, 224)\n",
            "199,677,411 FLOPs or approx. 0.20 GFLOPs\n",
            "pthflops:  199677411\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  Total MFLOPs  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference         5.61%     251.000us        73.84%       3.305ms       3.305ms       0.000us         0.00%       1.860ms       1.860ms             1            --  \n",
            "                                           aten::conv2d         0.27%      12.000us        62.87%       2.814ms       1.407ms       0.000us         0.00%       1.782ms     891.000us             2       393.291  \n",
            "                                      aten::convolution         0.60%      27.000us        62.60%       2.802ms       1.401ms       0.000us         0.00%       1.782ms     891.000us             2            --  \n",
            "                                     aten::_convolution         0.80%      36.000us        62.00%       2.775ms       1.387ms       0.000us         0.00%       1.782ms     891.000us             2            --  \n",
            "                                aten::cudnn_convolution        21.07%     943.000us        59.63%       2.669ms       1.335ms       1.759ms        94.57%       1.759ms     879.500us             2            --  \n",
            "             volta_scudnn_128x64_relu_xregs_large_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us       1.066ms        57.31%       1.066ms       1.066ms             1            --  \n",
            "void implicit_convolve_sgemm<float, float, 128, 5, 5...         0.00%       0.000us         0.00%       0.000us       0.000us     687.000us        36.94%     687.000us     687.000us             1            --  \n",
            "                                           aten::linear         0.25%      11.000us         3.19%     143.000us     143.000us       0.000us         0.00%      64.000us      64.000us             1            --  \n",
            "                                            aten::addmm         1.41%      63.000us         2.68%     120.000us     120.000us      64.000us         3.44%      64.000us      64.000us             1         5.092  \n",
            "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us      54.000us         2.90%      54.000us      54.000us             1            --  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 4.476ms\n",
            "Self CUDA time total: 1.860ms\n",
            "\n",
            "profiler:  199191660.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4ttFmxP2tYz"
      },
      "source": [
        "from torch.autograd import DeviceType\n",
        "\n",
        "def get_time_profiler(profiler):\n",
        "\n",
        "    events = profiler.events()\n",
        "    sum_self_cuda_time_total = 0\n",
        "    for evt in events:\n",
        "        if evt.device_type == DeviceType.CPU:\n",
        "            # in legacy profiler, kernel info is stored in cpu events\n",
        "            if evt.is_legacy:\n",
        "                sum_self_cuda_time_total += evt.self_cuda_time_total\n",
        "        elif evt.device_type == DeviceType.CUDA:\n",
        "            # in kineto profiler, there're events with the correct device type (e.g. CUDA)\n",
        "            sum_self_cuda_time_total += evt.self_cuda_time_total\n",
        "\n",
        "    return(sum_self_cuda_time_total)\n",
        "\n",
        "def get_time_epoch_profiler(model, trainloader): \n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    ### measure time\n",
        "    print(\"measure time\")\n",
        "    with torch.profiler.profile(\n",
        "        activities=[\n",
        "            torch.profiler.ProfilerActivity.CPU,\n",
        "            torch.profiler.ProfilerActivity.CUDA,\n",
        "        ]) as prof:\n",
        "        for x,y in trainloader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    time_ = get_time_profiler(profiler=prof)\n",
        "    return(time_)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0UVJU3B_Gc5"
      },
      "source": [
        "### test with TestNet\n",
        "#time_testnet = get_time_epoch_profiler(test_net, CIFAR10_testloader)\n",
        "#print(time_testnet / 1e6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZhAtMh4FAQP"
      },
      "source": [
        "### compute flops for one forward pass with one datapoint for all methods\n",
        "def get_flops_forward_all_methods(model): \n",
        "\n",
        "    flops_ptflops, num_params_ptflops = get_flops_ptflops(model, input_dims=(3, 224, 224))\n",
        "    flops_fvcore, num_params_fvcore = get_flops_fvcore(model, inputs=(torch.randn((1,3,224,224)).cuda(),))\n",
        "    flops_pthflops = get_flops_pthflops(model, inputs=torch.randn(1,3,224,224).cuda())\n",
        "    flops_profiler = get_flops_profiler(model, inputs=torch.randn((1,3,224,224)).cuda())\n",
        "\n",
        "    return(flops_ptflops, flops_fvcore, flops_pthflops, flops_profiler, num_params_fvcore)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkshX_ArFapr"
      },
      "source": [
        "### run the function for multiple models and batch_sizes\n",
        "\n",
        "def compare_model_batch_sizes(model, model_name, batch_sizes): \n",
        "\n",
        "    ### compute flops for one forward pass on one datapoint\n",
        "    flops_ptflops, flops_fvcore, flops_pthflops, flops_profiler, num_params_fvcore = get_flops_forward_all_methods(model)\n",
        "\n",
        "    ### compute times for different batch_sizes\n",
        "    batch_sizes_time_dict = dict()\n",
        "    for batch_size in batch_sizes:\n",
        "\n",
        "        print(\"model: {}; batch_size: {};\".format(model_name, batch_size))\n",
        "        ### define training data\n",
        "        testloader = torch.utils.data.DataLoader(CIFAR10_testset, batch_size=batch_size,\n",
        "                                        shuffle=True, num_workers=1)\n",
        "\n",
        "        ### compute flops for one epoch an training time for a bunch of epochs\n",
        "        time_epoch = get_time_epoch_profiler(model, testloader)\n",
        "\n",
        "        batch_sizes_time_dict[batch_size] = time_epoch\n",
        "\n",
        "    ### save results for current batch size in dict\n",
        "    results = {\n",
        "        \"flops_ptflops_forward\":flops_ptflops,\n",
        "        \"flops_fvcore_forward\":flops_fvcore,\n",
        "        \"flops_pthflops_forward\":flops_pthflops,\n",
        "        \"flops_profiler_forward\":flops_profiler,\n",
        "        \"num_params\":num_params_fvcore,\n",
        "        \"time_epoch_batch_sizes\":batch_sizes_time_dict\n",
        "    }\n",
        "    print(results)\n",
        "\n",
        "    return(results)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z8tzoFdSkQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f74ec4d-e21a-4ec6-c857-2a0e26fd1c70"
      },
      "source": [
        "#batch_sizes_test = [256, 128, 64]\n",
        "#batch_sizes_test = [128, 64]\n",
        "batch_sizes_test = [64]\n",
        "#model, model_name = test_net, \"test_net\"\n",
        "#model, model_name = resnet18, \"resnet18\"\n",
        "#model, model_name = resnet34, \"resnet34\"\n",
        "#model, model_name = resnet50, \"resnet50\"\n",
        "#model, model_name = resnet101, \"resnet101\"\n",
        "#model, model_name = resnet152, \"resnet152\"\n",
        "#model, model_name = vgg11, \"vgg11\"\n",
        "#model, model_name = vgg13, \"vgg13\" \n",
        "#model, model_name = vgg16, \"vgg16\"\n",
        "#model, model_name = vgg19, \"vgg19\"\n",
        "#model, model_name = wide_resnet50_2, \"wide_resnet50_2\"\n",
        "#model, model_name = alexnet, \"alexnet\"\n",
        "#model, model_name = mobilenet_v2, \"mobilenet_v2\"\n",
        "model, model_name = efficientnet_b0, \"efficientnet_b0\"\n",
        "t0 = time.time()\n",
        "results_dict = compare_model_batch_sizes(model, model_name, batch_sizes_test)\n",
        "t1 = time.time()\n",
        "print(\"comparing models took {} seconds\".format(t1 - t0))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::silu_ encountered 49 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sigmoid encountered 16 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 16 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 9 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::dropout_ encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "features.1.0.stochastic_depth, features.2.0.stochastic_depth, features.2.1.stochastic_depth, features.3.0.stochastic_depth, features.3.1.stochastic_depth, features.4.0.stochastic_depth, features.4.1.stochastic_depth, features.4.2.stochastic_depth, features.5.0.stochastic_depth, features.5.1.stochastic_depth, features.5.2.stochastic_depth, features.6.0.stochastic_depth, features.6.1.stochastic_depth, features.6.2.stochastic_depth, features.6.3.stochastic_depth, features.7.0.stochastic_depth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operation                      OPS        \n",
            "-----------------------------  ---------  \n",
            "features_0_0                   10838016   \n",
            "features_0_1                   802816     \n",
            "features_1_0_block_0_0         3612672    \n",
            "features_1_0_block_0_1         802816     \n",
            "features_1_0_block_1_avgpool   401408     \n",
            "features_1_0_block_1_fc1       264        \n",
            "features_1_0_block_1_fc2       288        \n",
            "mul                            802816     \n",
            "features_1_0_block_2_0         6422528    \n",
            "features_1_0_block_2_1         401408     \n",
            "features_2_0_block_0_0         19267584   \n",
            "features_2_0_block_0_1         2408448    \n",
            "features_2_0_block_1_0         2709504    \n",
            "features_2_0_block_1_1         602112     \n",
            "features_2_0_block_2_avgpool   301056     \n",
            "features_2_0_block_2_fc1       388        \n",
            "features_2_0_block_2_fc2       480        \n",
            "mul_1                          602112     \n",
            "features_2_0_block_3_0         7225344    \n",
            "features_2_0_block_3_1         150528     \n",
            "features_2_1_block_0_0         10838016   \n",
            "features_2_1_block_0_1         903168     \n",
            "features_2_1_block_1_0         4064256    \n",
            "features_2_1_block_1_1         903168     \n",
            "features_2_1_block_2_avgpool   451584     \n",
            "features_2_1_block_2_fc1       870        \n",
            "features_2_1_block_2_fc2       1008       \n",
            "mul_2                          903168     \n",
            "features_2_1_block_3_0         10838016   \n",
            "features_2_1_block_3_1         150528     \n",
            "add                            150528     \n",
            "features_3_0_block_0_0         10838016   \n",
            "features_3_0_block_0_1         903168     \n",
            "features_3_0_block_1_0         2822400    \n",
            "features_3_0_block_1_1         225792     \n",
            "features_3_0_block_2_avgpool   112896     \n",
            "features_3_0_block_2_fc1       870        \n",
            "features_3_0_block_2_fc2       1008       \n",
            "mul_3                          225792     \n",
            "features_3_0_block_3_0         4515840    \n",
            "features_3_0_block_3_1         62720      \n",
            "features_3_1_block_0_0         7526400    \n",
            "features_3_1_block_0_1         376320     \n",
            "features_3_1_block_1_0         4704000    \n",
            "features_3_1_block_1_1         376320     \n",
            "features_3_1_block_2_avgpool   188160     \n",
            "features_3_1_block_2_fc1       2410       \n",
            "features_3_1_block_2_fc2       2640       \n",
            "mul_4                          376320     \n",
            "features_3_1_block_3_0         7526400    \n",
            "features_3_1_block_3_1         62720      \n",
            "add_1                          62720      \n",
            "features_4_0_block_0_0         7526400    \n",
            "features_4_0_block_0_1         376320     \n",
            "features_4_0_block_1_0         423360     \n",
            "features_4_0_block_1_1         94080      \n",
            "features_4_0_block_2_avgpool   47040      \n",
            "features_4_0_block_2_fc1       2410       \n",
            "features_4_0_block_2_fc2       2640       \n",
            "mul_5                          94080      \n",
            "features_4_0_block_3_0         3763200    \n",
            "features_4_0_block_3_1         31360      \n",
            "features_4_1_block_0_0         7526400    \n",
            "features_4_1_block_0_1         188160     \n",
            "features_4_1_block_1_0         846720     \n",
            "features_4_1_block_1_1         188160     \n",
            "features_4_1_block_2_avgpool   94080      \n",
            "features_4_1_block_2_fc1       9620       \n",
            "features_4_1_block_2_fc2       10080      \n",
            "mul_6                          188160     \n",
            "features_4_1_block_3_0         7526400    \n",
            "features_4_1_block_3_1         31360      \n",
            "add_2                          31360      \n",
            "features_4_2_block_0_0         7526400    \n",
            "features_4_2_block_0_1         188160     \n",
            "features_4_2_block_1_0         846720     \n",
            "features_4_2_block_1_1         188160     \n",
            "features_4_2_block_2_avgpool   94080      \n",
            "features_4_2_block_2_fc1       9620       \n",
            "features_4_2_block_2_fc2       10080      \n",
            "mul_7                          188160     \n",
            "features_4_2_block_3_0         7526400    \n",
            "features_4_2_block_3_1         31360      \n",
            "add_3                          31360      \n",
            "features_5_0_block_0_0         7526400    \n",
            "features_5_0_block_0_1         188160     \n",
            "features_5_0_block_1_0         2352000    \n",
            "features_5_0_block_1_1         188160     \n",
            "features_5_0_block_2_avgpool   94080      \n",
            "features_5_0_block_2_fc1       9620       \n",
            "features_5_0_block_2_fc2       10080      \n",
            "mul_8                          188160     \n",
            "features_5_0_block_3_0         10536960   \n",
            "features_5_0_block_3_1         43904      \n",
            "features_5_1_block_0_0         14751744   \n",
            "features_5_1_block_0_1         263424     \n",
            "features_5_1_block_1_0         3292800    \n",
            "features_5_1_block_1_1         263424     \n",
            "features_5_1_block_2_avgpool   131712     \n",
            "features_5_1_block_2_fc1       18844      \n",
            "features_5_1_block_2_fc2       19488      \n",
            "mul_9                          263424     \n",
            "features_5_1_block_3_0         14751744   \n",
            "features_5_1_block_3_1         43904      \n",
            "add_4                          43904      \n",
            "features_5_2_block_0_0         14751744   \n",
            "features_5_2_block_0_1         263424     \n",
            "features_5_2_block_1_0         3292800    \n",
            "features_5_2_block_1_1         263424     \n",
            "features_5_2_block_2_avgpool   131712     \n",
            "features_5_2_block_2_fc1       18844      \n",
            "features_5_2_block_2_fc2       19488      \n",
            "mul_10                         263424     \n",
            "features_5_2_block_3_0         14751744   \n",
            "features_5_2_block_3_1         43904      \n",
            "add_5                          43904      \n",
            "features_6_0_block_0_0         14751744   \n",
            "features_6_0_block_0_1         263424     \n",
            "features_6_0_block_1_0         823200     \n",
            "features_6_0_block_1_1         65856      \n",
            "features_6_0_block_2_avgpool   32928      \n",
            "features_6_0_block_2_fc1       18844      \n",
            "features_6_0_block_2_fc2       19488      \n",
            "mul_11                         65856      \n",
            "features_6_0_block_3_0         6322176    \n",
            "features_6_0_block_3_1         18816      \n",
            "features_6_1_block_0_0         10838016   \n",
            "features_6_1_block_0_1         112896     \n",
            "features_6_1_block_1_0         1411200    \n",
            "features_6_1_block_1_1         112896     \n",
            "features_6_1_block_2_avgpool   56448      \n",
            "features_6_1_block_2_fc1       55344      \n",
            "features_6_1_block_2_fc2       56448      \n",
            "mul_12                         112896     \n",
            "features_6_1_block_3_0         10838016   \n",
            "features_6_1_block_3_1         18816      \n",
            "add_6                          18816      \n",
            "features_6_2_block_0_0         10838016   \n",
            "features_6_2_block_0_1         112896     \n",
            "features_6_2_block_1_0         1411200    \n",
            "features_6_2_block_1_1         112896     \n",
            "features_6_2_block_2_avgpool   56448      \n",
            "features_6_2_block_2_fc1       55344      \n",
            "features_6_2_block_2_fc2       56448      \n",
            "mul_13                         112896     \n",
            "features_6_2_block_3_0         10838016   \n",
            "features_6_2_block_3_1         18816      \n",
            "add_7                          18816      \n",
            "features_6_3_block_0_0         10838016   \n",
            "features_6_3_block_0_1         112896     \n",
            "features_6_3_block_1_0         1411200    \n",
            "features_6_3_block_1_1         112896     \n",
            "features_6_3_block_2_avgpool   56448      \n",
            "features_6_3_block_2_fc1       55344      \n",
            "features_6_3_block_2_fc2       56448      \n",
            "mul_14                         112896     \n",
            "features_6_3_block_3_0         10838016   \n",
            "features_6_3_block_3_1         18816      \n",
            "add_8                          18816      \n",
            "features_7_0_block_0_0         10838016   \n",
            "features_7_0_block_0_1         112896     \n",
            "features_7_0_block_1_0         508032     \n",
            "features_7_0_block_1_1         112896     \n",
            "features_7_0_block_2_avgpool   56448      \n",
            "features_7_0_block_2_fc1       55344      \n",
            "features_7_0_block_2_fc2       56448      \n",
            "mul_15                         112896     \n",
            "features_7_0_block_3_0         18063360   \n",
            "features_7_0_block_3_1         31360      \n",
            "features_8_0                   20070400   \n",
            "features_8_1                   125440     \n",
            "avgpool                        62720      \n",
            "classifier_1                   12810      \n",
            "----------------------------   --------   \n",
            "Input size: (1, 3, 224, 224)\n",
            "405,434,822 FLOPs or approx. 0.41 GFLOPs\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  Total KFLOPs  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference        21.00%       5.975ms        99.88%      28.424ms      28.424ms       0.000us         0.00%       6.157ms       6.157ms             1            --  \n",
            "                                           aten::conv2d         1.14%     324.000us        43.80%      12.465ms     153.889us       0.000us         0.00%       4.491ms      55.444us            81    769069.504  \n",
            "                                      aten::convolution         2.56%     729.000us        42.66%      12.141ms     149.889us       0.000us         0.00%       4.491ms      55.444us            81            --  \n",
            "                                     aten::_convolution         2.33%     662.000us        40.10%      11.412ms     140.889us       0.000us         0.00%       4.491ms      55.444us            81            --  \n",
            "                                aten::cudnn_convolution        20.15%       5.735ms        31.85%       9.063ms     139.431us       3.740ms        60.74%       3.740ms      57.538us            65            --  \n",
            "void implicit_convolve_sgemm<float, float, 1024, 5, ...         0.00%       0.000us         0.00%       0.000us       0.000us       1.365ms        22.17%       1.365ms      59.348us            23            --  \n",
            "                                            aten::silu_         2.56%     729.000us        14.38%       4.093ms      83.531us     347.000us         5.64%     690.000us      14.082us            49            --  \n",
            "                volta_scudnn_128x64_relu_interior_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     676.000us        10.98%     676.000us      52.000us            13            --  \n",
            "                                aten::_conv_depthwise2d         0.65%     186.000us         3.49%     994.000us      62.125us     623.000us        10.12%     623.000us      38.938us            16            --  \n",
            "                                       aten::batch_norm         0.41%     116.000us        13.48%       3.836ms      78.286us       0.000us         0.00%     497.000us      10.143us            49            --  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 28.457ms\n",
            "Self CUDA time total: 6.157ms\n",
            "\n",
            "model: efficientnet_b0; batch_size: 64;\n",
            "measure time\n",
            "{'flops_ptflops_forward': 400401542.0, 'flops_fvcore_forward': 400392192, 'flops_pthflops_forward': 405434822, 'flops_profiler_forward': 384552032.0, 'num_params': 4020358, 'time_epoch_batch_sizes': {64: 46360468}}\n",
            "comparing models took 117.94009160995483 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtIGQoTB9z7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29503e3a-3d6f-46f0-9f26-86c996046ed1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 30 23:19:21 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    29W /  70W |  10432MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cBXG2hvbl2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a903c86-844d-4737-b8ef-2fa061b55a5c"
      },
      "source": [
        "results_dict"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flops_ptflops_forward': 400401542.0,\n",
              " 'flops_fvcore_forward': 400392192,\n",
              " 'flops_pthflops_forward': 405434822,\n",
              " 'flops_profiler_forward': 384552032.0,\n",
              " 'num_params': 4020358,\n",
              " 'time_epoch_batch_sizes': {64: 46360468}}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp7szhwf-65C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "154a6bfc-219a-4f32-adac-4a0002d9a1ed"
      },
      "source": [
        "### don't forget to name the GPU that you were using and the right model class (e.g. resnets)\n",
        "GPU_type = \"Tesla_P100\"\n",
        "results_dict['GPU_type'] = GPU_type\n",
        "torch.save(results_dict, data_file_location + \"{}_flops_time_{}.pt\".format(model_name, GPU_type))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-684531ee4ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mGPU_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Tesla_P100\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GPU_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPU_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file_location\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{}_flops_time_{}.pt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPU_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Parameters, Compute and Data Trends in Machine Learning/empirical_FLOPs/data/efficientnet_b0_flops_time_Tesla_P100.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqh29__2rn99"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, from here on I'll add some loops to use some of the functions above over all the models above.\n",
        "\n",
        "List of the models:\n",
        "\n",
        "resnet18\n",
        "\n",
        "resnet34\n",
        "\n",
        "resnet50\n",
        "\n",
        "resnet101\n",
        "\n",
        "resnet152\n",
        "\n",
        "vgg11\n",
        "\n",
        "vgg13\n",
        "\n",
        "vgg16\n",
        "\n",
        "vgg19\n",
        "\n",
        "wide_resnet50_2 \n",
        "\n",
        "alexnet\n",
        "\n",
        "mobilenet_v2\n",
        "\n",
        "efficientnet_b0 "
      ],
      "metadata": {
        "id": "lv1aZrbf7Jyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_size(model):\n",
        "  #credit to ptrblack on the pytorch forums for this bit of code\n",
        "  #https://discuss.pytorch.org/t/finding-model-size/130275\n",
        "  param_size = 0\n",
        "  buffer_size = 0\n",
        "  for param in model.parameters():\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "  for buffer in model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "  size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "  return size_all_mb\n",
        "\n",
        "flops_per_model = {}\n",
        "size_per_model = {}\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(resnet18)\n",
        "flops_per_model['resnet18'] = flops_ptflops\n",
        "size_per_model['resnet18'] = get_size(resnet18)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(resnet34)\n",
        "flops_per_model['resnet34'] = flops_ptflops\n",
        "size_per_model['resnet34'] = get_size(resnet34)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(resnet50)\n",
        "flops_per_model['resnet50'] = flops_ptflops\n",
        "size_per_model['resnet50'] = get_size(resnet50)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(resnet101)\n",
        "flops_per_model['resnet101'] = flops_ptflops\n",
        "size_per_model['resnet101'] = get_size(resnet101)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(resnet152)\n",
        "flops_per_model['resnet152'] = flops_ptflops\n",
        "size_per_model['resnet152'] = get_size(resnet152)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(vgg11)\n",
        "flops_per_model['vgg11'] = flops_ptflops\n",
        "size_per_model['vgg11'] = get_size(vgg11)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(vgg13)\n",
        "flops_per_model['vgg13'] = flops_ptflops\n",
        "size_per_model['vgg13'] = get_size(vgg13)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(vgg16)\n",
        "flops_per_model['vgg16'] = flops_ptflops\n",
        "size_per_model['vgg16'] = get_size(vgg16)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(vgg19)\n",
        "flops_per_model['vgg19'] = flops_ptflops\n",
        "size_per_model['vgg19'] = get_size(vgg19)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(wide_resnet50_2)\n",
        "flops_per_model['wide_resnet50_2'] = flops_ptflops\n",
        "size_per_model['wide_resnet50_2'] = get_size(wide_resnet50_2)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(alexnet)\n",
        "flops_per_model['alexnet'] = flops_ptflops\n",
        "size_per_model['alexnet'] = get_size(alexnet)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(mobilenet_v2)\n",
        "flops_per_model['mobilenet_v2'] = flops_ptflops\n",
        "size_per_model['mobilenet_v2'] = get_size(mobilenet_v2)\n",
        "\n",
        "flops_ptflops, num_params_ptflops = get_flops_ptflops(efficientnet_b0)\n",
        "flops_per_model['efficientnet_b0'] = flops_ptflops\n",
        "size_per_model['efficientnet_b0'] = get_size(efficientnet_b0)\n",
        "\n",
        "print(flops_per_model)\n",
        "print(size_per_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bbKYLHvAApK",
        "outputId": "33595cf1-0981-4733-d129-f9232bd022cc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'resnet18': 1821669898.0, 'resnet34': 3675121162.0, 'resnet50': 4119896586.0, 'resnet101': 7847471626.0, 'resnet152': 11578659338.0, 'vgg11': 7626050058.0, 'vgg13': 11335059978.0, 'vgg16': 15499467274.0, 'vgg19': 19663874570.0, 'wide_resnet50_2': 11438593034.0, 'alexnet': 711505866.0, 'mobilenet_v2': 318969098.0, 'efficientnet_b0': 400401542.0}\n",
            "{'resnet18': 42.69135284423828, 'resnet34': 81.27936553955078, 'resnet50': 89.95722961425781, 'resnet101': 162.6060562133789, 'resnet152': 222.4580078125, 'vgg11': 491.36087799072266, 'vgg13': 492.06473541259766, 'vgg16': 512.3196182250977, 'vgg19': 532.5745010375977, 'wide_resnet50_2': 255.2912139892578, 'alexnet': 217.60868072509766, 'mobilenet_v2': 8.662788391113281, 'efficientnet_b0': 15.497100830078125}\n"
          ]
        }
      ]
    }
  ]
}